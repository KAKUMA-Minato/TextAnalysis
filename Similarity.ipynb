{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Similarity.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KAKUMA-Minato/TextAnalysis/blob/master/Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aVVn6hB9Zei",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing and calculate similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5-315WVmN64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "8ddec198-894c-4aaa-e29a-6254ea3dd0f6"
      },
      "source": [
        "# 必要なパッケージのインストール\n",
        "!pip install nltk\n",
        "!pip install gensim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.14.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.9 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.17.9)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8iK7xBDTmtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBUvXHj7mRls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "549e2b69-0b6f-44fc-b7d2-05a265391886"
      },
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbmC0C6tF9Pn",
        "colab_type": "text"
      },
      "source": [
        "用いるドキュメント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxkC7A9iuyO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs = [\"Japan is an island country in East Asia. Located in the Pacific Ocean, it lies off the eastern coast of the Asian continent and stretches from the Sea of Okhotsk in the north to the East China Sea and the Philippine Sea in the south.\",\"The United States of America (USA), commonly known as the United States (U.S. or US) or America, is a country comprising 50 states, a federal district, five major self-governing territories, and various possessions.\",\"England is a country that is part of the United Kingdom.\",\"China, officially the People's Republic of China (PRC), is a country in East Asia and the world's most populous country, with a population of around 1.404 billion.\",\"India, also known as the Republic of India,[19][e] is a country in South Asia.\",\"Korea is a region in East Asia.\",\"Germany, officially the Federal Republic of Germany is a country in Central and Western Europe, lying between the Baltic and North Seas to the north, and the Alps, Lake Constance and the High Rhine to the south.\",\"Russia, or the Russian Federation[12], is a transcontinental country in Eastern Europe and North Asia.\",\"France, officially the French Republic, is a country whose territory consists of metropolitan France in Western Europe and several overseas regions and territories.\",\"Italy, officially the Italian Republic,[10][11][12][13] is a European country consisting of a peninsula delimited by the Italian Alps and surrounded by several islands.\",\"Brazil officially the Federative Republic of Brazil [9] is the largest country in both South America and Latin America.\",\"Canada is a country in the northern part of North America.\",\"Spain, officially the Kingdom of Spain[11][a][b] is a country mostly located in Europe.\",\"Australia, officially the Commonwealth of Australia,[12] is a sovereign country comprising the mainland of the Australian continent, the island of Tasmania, and numerous smaller islands.\",\"Indonesia, officially the Republic of Indonesia (Indonesian: Republik Indonesia [reˈpublik ɪndoˈnesia])[a], is a country in Southeast Asia, between the Indian and Pacific oceans.\",\"Mexico, officially the United Mexican States (Spanish: Estados Unidos Mexicanos[10][11][12][13], is a country in the southern portion of North America.\"]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "divym-mDnoyP",
        "colab_type": "text"
      },
      "source": [
        "##前処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuXSHk01KLza",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kXJ0XKXx3vE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_stop = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpQzg57nSAT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing_text(text):\n",
        "  def cleaning_text(text):\n",
        "    # @の削除\n",
        "    pattern1 = '@|%'\n",
        "    text = re.sub(pattern1, '', text)    \n",
        "    pattern2 = '\\[[0-9 ]*\\]'\n",
        "    text = re.sub(pattern2, '', text)    \n",
        "    # <b>タグの削除\n",
        "    pattern3 = '\\([a-z ]*\\)'\n",
        "    text = re.sub(pattern3, '', text)    \n",
        "    pattern4 = '[0-9]'\n",
        "    text = re.sub(pattern4, '', text)\n",
        "    return text\n",
        "  \n",
        "  def tokenize_text(text):\n",
        "    text = re.sub('[.,]', '', text)\n",
        "    return text.split()\n",
        "\n",
        "  def remove_stopwords(word, stopwordset):\n",
        "    if word in stopwordset:\n",
        "       return None\n",
        "    else:\n",
        "       return word  \n",
        "\n",
        "  def lemmatize_word(word):\n",
        "    # make words lower  example: Python =>python\n",
        "    word=word.lower()\n",
        "    \n",
        "    # lemmatize  example: cooked=>cook\n",
        "    lemma = wn.morphy(word)\n",
        "    if lemma is None:\n",
        "        return word\n",
        "    else:\n",
        "      return lemma\n",
        "    \n",
        "  text = cleaning_text(text)\n",
        "  tokens = tokenize_text(text)\n",
        "  tokens = [lemmatize_word(word) for word in tokens]\n",
        "  tokens = [remove_stopwords(word, en_stop) for word in tokens]\n",
        "  tokens = [word for word in tokens if word is not None]\n",
        "  return tokens\n",
        "  \n",
        "preprocessed_docs = [preprocessing_text(text) for text in docs]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKl3UOkO6XWF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc2862ba-e2fe-43f2-edfc-1c9ce0a5a669"
      },
      "source": [
        "print(preprocessed_docs[0])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['japan', 'island', 'country', 'east', 'asia', 'locate', 'pacific', 'ocean', 'lie', 'eastern', 'coast', 'asian', 'continent', 'stretch', 'sea', 'okhotsk', 'north', 'east', 'china', 'sea', 'philippine', 'sea', 'south']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpg2beFhKA2R",
        "colab_type": "text"
      },
      "source": [
        "## Calculate similarity\n",
        "\n",
        "- 1 集合ベースの類似度\n",
        "  - 1.1 Jaccard係数\n",
        "  - 1.2 Dice係数\n",
        "  - 1.3 Simpson係数\n",
        "- 2 ベクトルベースの類似度\n",
        "  - 2.1 ユークリッド距離\n",
        "  - 2.2コサイン類似度\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1rpPCaUeOWE",
        "colab_type": "text"
      },
      "source": [
        "### 1 集合ベース\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uts5Ns2eKDaW",
        "colab_type": "text"
      },
      "source": [
        "#### 1.1Jaccard係数\n",
        "Jaccard係数は二つの集合A,Bに対して定義される類似度である  \n",
        "計算式は以下の通り\n",
        "\n",
        "\\begin{equation}\n",
        "J(A,B)=\\dfrac{|A\\cap B|}{|A \\cup B|}\n",
        "\\end{equation}\n",
        "\n",
        "共通部分の割合が大きければその二つの文書は似ていると考える"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZSFY5urK8eT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "17d38aab-97c8-4334-b23f-dc0c9704f622"
      },
      "source": [
        "from nltk.metrics import jaccard_distance\n",
        "\n",
        "for i in range(16):\n",
        "   set_0 = set(preprocessed_docs[0])\n",
        "   set_i = set(preprocessed_docs[i])\n",
        "   print(\"jaccard(0,\",i,\") = \", 1 - jaccard_distance(set_0, set_i))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jaccard(0, 0 ) =  1.0\n",
            "jaccard(0, 1 ) =  0.027027027027026973\n",
            "jaccard(0, 2 ) =  0.04166666666666663\n",
            "jaccard(0, 3 ) =  0.13793103448275867\n",
            "jaccard(0, 4 ) =  0.12\n",
            "jaccard(0, 5 ) =  0.09090909090909094\n",
            "jaccard(0, 6 ) =  0.11764705882352944\n",
            "jaccard(0, 7 ) =  0.16000000000000003\n",
            "jaccard(0, 8 ) =  0.030303030303030276\n",
            "jaccard(0, 9 ) =  0.06451612903225812\n",
            "jaccard(0, 10 ) =  0.07407407407407407\n",
            "jaccard(0, 11 ) =  0.08333333333333337\n",
            "jaccard(0, 12 ) =  0.07692307692307687\n",
            "jaccard(0, 13 ) =  0.09999999999999998\n",
            "jaccard(0, 14 ) =  0.13793103448275867\n",
            "jaccard(0, 15 ) =  0.0625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lyCVTfePwB2",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2 Sørensen-Dice係数\n",
        "\n",
        "Jaccard係数では分母はの和集合であったため  \n",
        "片方の集合がとても大きいと共通部分が大きくても係数の値が小さくなってしまうという問題がある  \n",
        "Sørensen-Dice係数では、分母を二つの集合の大きさの平均をとることで、その影響を緩和している  \n",
        "\n",
        "$\n",
        "DSC(A,B) = \\dfrac{|A\\cap B|}{\\dfrac{|A| + |B|}{2}} = \\dfrac{2|A\\cap B|}{|A| + |B|}\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M0RikFPR3Qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_similarity(set_a, set_b):\n",
        "  num_intersection =  len(set.intersection(set_a, set_b))\n",
        "  sum_nums = len(set_a) + len(set_b)\n",
        "  try:\n",
        "    return 2 * num_intersection / sum_nums\n",
        "  except ZeroDivisionError:\n",
        "    return 1.0 "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPhuPKBM_BM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d95aa0b5-bbde-4ccd-8711-b23c71a42c22"
      },
      "source": [
        "for i in range(16):\n",
        "   set_0 = set(preprocessed_docs[0])\n",
        "   set_i = set(preprocessed_docs[i])\n",
        "   print(\"dice(0,\",i,\") = \", dice_similarity(set_0, set_i))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dice(0, 0 ) =  1.0\n",
            "dice(0, 1 ) =  0.05263157894736842\n",
            "dice(0, 2 ) =  0.08\n",
            "dice(0, 3 ) =  0.24242424242424243\n",
            "dice(0, 4 ) =  0.21428571428571427\n",
            "dice(0, 5 ) =  0.16666666666666666\n",
            "dice(0, 6 ) =  0.21052631578947367\n",
            "dice(0, 7 ) =  0.27586206896551724\n",
            "dice(0, 8 ) =  0.058823529411764705\n",
            "dice(0, 9 ) =  0.12121212121212122\n",
            "dice(0, 10 ) =  0.13793103448275862\n",
            "dice(0, 11 ) =  0.15384615384615385\n",
            "dice(0, 12 ) =  0.14285714285714285\n",
            "dice(0, 13 ) =  0.18181818181818182\n",
            "dice(0, 14 ) =  0.24242424242424243\n",
            "dice(0, 15 ) =  0.11764705882352941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxtliI-HPwRE",
        "colab_type": "text"
      },
      "source": [
        "#### 1.3 Szymkiewicz-Simpson係数\n",
        "\n",
        "差集合の要素数の影響を極限まで抑えたのがSzymkiewicz-Simpson係数    \n",
        "$\n",
        "overlap(𝐴,𝐵) = \\dfrac{|A\\cap B|}{\\min(|A|, |B|)}\n",
        "$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgGJ5GhmUduH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simpson_similarity(list_a, list_b):\n",
        "  num_intersection = len(set.intersection(set(list_a), set(list_b)))\n",
        "  min_num = min(len(set(list_a)), len(set(list_b)))\n",
        "  try:\n",
        "    return num_intersection / min_num\n",
        "  except ZeroDivisionError:\n",
        "    if num_intersection == 0:\n",
        "      return 1.0\n",
        "    else:\n",
        "      return 0"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tszacdug_NWq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "2d33b307-a972-4c5c-f11c-64e255a6390f"
      },
      "source": [
        "for i in range(16):\n",
        "   set_0 = set(preprocessed_docs[0])\n",
        "   set_i = set(preprocessed_docs[i])\n",
        "   print(\"simpson(0,\",i,\") = \", simpson_similarity(set_0, set_i))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "simpson(0, 0 ) =  1.0\n",
            "simpson(0, 1 ) =  0.05555555555555555\n",
            "simpson(0, 2 ) =  0.2\n",
            "simpson(0, 3 ) =  0.3076923076923077\n",
            "simpson(0, 4 ) =  0.375\n",
            "simpson(0, 5 ) =  0.5\n",
            "simpson(0, 6 ) =  0.2222222222222222\n",
            "simpson(0, 7 ) =  0.4444444444444444\n",
            "simpson(0, 8 ) =  0.07142857142857142\n",
            "simpson(0, 9 ) =  0.15384615384615385\n",
            "simpson(0, 10 ) =  0.2222222222222222\n",
            "simpson(0, 11 ) =  0.3333333333333333\n",
            "simpson(0, 12 ) =  0.25\n",
            "simpson(0, 13 ) =  0.23076923076923078\n",
            "simpson(0, 14 ) =  0.3076923076923077\n",
            "simpson(0, 15 ) =  0.14285714285714285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-Hm34tgXCbh",
        "colab_type": "text"
      },
      "source": [
        "### 2 ベクトルベース "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e8h1SMTcyD5",
        "colab_type": "text"
      },
      "source": [
        "### TF-IDF(Term Frequency - Inverse Document Frequency)\n",
        "\n",
        "BoWでは各単語の重みが同じだったが、単語によって重要度は変わる  \n",
        "単語の重要度を考慮したのがTF-IDF  \n",
        "\n",
        "TF(t, d) = ある単語(t)のある文書(d)における出現頻度  \n",
        "IDF(t) = ある単語(t)が全文書集合(D)中にどれだけの文書で出現したかの逆数  \n",
        "\n",
        "TF-IDF(t,d) = TF(t, d) * IDF(t)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiKn2p7Bc0bN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tfidf_vectorizer(docs):\n",
        "  def tf(word2id, doc):\n",
        "    term_counts = np.zeros(len(word2id))\n",
        "    for term in word2id.keys():\n",
        "      term_counts[word2id[term]] = doc.count(term)\n",
        "    tf_values = list(map(lambda x: x/sum(term_counts), term_counts))\n",
        "    return tf_values\n",
        "  \n",
        "  def idf(word2id, docs):\n",
        "    idf = np.zeros(len(word2id))\n",
        "    for term in word2id.keys():\n",
        "      idf[word2id[term]] = np.log(len(docs) / sum([bool(term in doc) for doc in docs]))\n",
        "    return idf\n",
        "  \n",
        "  word2id = {}\n",
        "  for doc in docs:\n",
        "    for w in doc:\n",
        "      if w not in word2id:\n",
        "        word2id[w] = len(word2id)\n",
        "  \n",
        "  return [[_tf*_idf for _tf, _idf in zip(tf(word2id, doc), idf(word2id, docs))] for doc in docs], word2id\n",
        "  "
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz5YnQZclGfL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "19cc3a3e-0d83-423c-dc0f-557f8124023c"
      },
      "source": [
        "tfidf_vector, word2id = tfidf_vectorizer(preprocessed_docs)\n",
        "print(tfidf_vector)\n",
        "print(word2id.items())"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1205473357495557, 0.07278158406833354, 0.0028060226581552677, 0.1455631681366671, 0.04264475013094462, 0.09041050181216677, 0.09041050181216677, 0.09041050181216677, 0.1205473357495557, 0.09041050181216677, 0.1205473357495557, 0.1205473357495557, 0.09041050181216677, 0.1205473357495557, 0.2712315054365003, 0.1205473357495557, 0.05057177433937743, 0.09041050181216677, 0.1205473357495557, 0.06027366787477785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.002933569142616871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15217967577924288, 0.28356021022906847, 0.12602676010180824, 0.12602676010180824, 0.12602676010180824, 0.09452007007635617, 0.12602676010180824, 0.12602676010180824, 0.09452007007635617, 0.09452007007635617, 0.12602676010180824, 0.12602676010180824, 0.12602676010180824, 0.12602676010180824, 0.09452007007635617, 0.12602676010180824, 0.12602676010180824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.012907704227514234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33479528671433434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5545177444479562, 0.4158883083359672, 0.4158883083359672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.008605136151676155, 0.1115984289047781, 0.06538861686744842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2772588722239781, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038357609660237456, 0.18483924814931874, 0.05511190487896453, 0.18483924814931874, 0.18483924814931874, 0.18483924814931874, 0.18483924814931874, 0.18483924814931874, 0.18483924814931874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.008067315142196396, 0.0, 0.12260365662646577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17328679513998632, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25993019270997947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10333482164805849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34657359027997264, 0.34657359027997264, 0.34657359027997264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.4184941083929179, 0.24520731325293155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6931471805599453, 0.5198603854199589, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0032269260568785585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1039720770839918, 0.0, 0.11631508098056809, 0.0, 0.0, 0.06931471805599453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1039720770839918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02876820724517809, 0.0, 0.0413339286592234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2772588722239781, 0.13862943611198905, 0.1039720770839918, 0.06931471805599453, 0.13862943611198905, 0.13862943611198905, 0.1039720770839918, 0.13862943611198905, 0.13862943611198905, 0.13862943611198905, 0.13862943611198905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.007170946793063462, 0.0, 0.10898102811241402, 0.0, 0.0, 0.0, 0.0, 0.2310490601866484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12923897886729788, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15403270679109896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3080654135821979, 0.3080654135821979, 0.3080654135821979, 0.3080654135821979, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.004033657571098198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25993019270997947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03596025905647261, 0.0, 0.051667410824029245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12996509635498973, 0.0, 0.0, 0.12996509635498973, 0.08664339756999316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34657359027997264, 0.17328679513998632, 0.17328679513998632, 0.12996509635498973, 0.17328679513998632, 0.12996509635498973, 0.17328679513998632, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.11956974525511939, 0.004609894366969369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04109743892168299, 0.0, 0.05904846951317628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14853153869141683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14853153869141683, 0.0, 0.14853153869141683, 0.0, 0.19804205158855578, 0.39608410317711157, 0.19804205158855578, 0.19804205158855578, 0.19804205158855578, 0.19804205158855578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.005867138285233742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12602676010180824, 0.0, 0.0, 0.2520535202036165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052305831354869256, 0.0, 0.07515259756222435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.504107040407233, 0.2520535202036165, 0.2520535202036165, 0.2520535202036165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.010756420189595193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1938584683009468, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23104906018664842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3465735902799726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.46209812037329684, 0.46209812037329684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.008067315142196396, 0.0, 0.0, 0.25993019270997947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25993019270997947, 0.07192051811294523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17328679513998632, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34657359027997264, 0.34657359027997264, 0.34657359027997264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.2231968578095562, 0.004302568075838078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13862943611198905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13862943611198905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038357609660237456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36967849629863747, 0.18483924814931874, 0.18483924814931874, 0.18483924814931874, 0.18483924814931874, 0.18483924814931874, 0.18483924814931874, 0.18483924814931874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.004302568075838078, 0.0, 0.06538861686744842, 0.0, 0.13862943611198905, 0.13862943611198905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038357609660237456, 0.0, 0.05511190487896453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5545177444479562, 0.18483924814931874, 0.18483924814931874, 0.18483924814931874, 0.18483924814931874, 0.18483924814931874, 0.18483924814931874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.004609894366969369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08308220070040577, 0.0, 0.0, 0.0, 0.11956974525511939, 0.14853153869141683, 0.09902102579427789, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04109743892168299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19804205158855578, 0.19804205158855578, 0.19804205158855578, 0.19804205158855578, 0.19804205158855578, 0.19804205158855578, 0.19804205158855578, 0.19804205158855578]]\n",
            "dict_items([('japan', 0), ('island', 1), ('country', 2), ('east', 3), ('asia', 4), ('locate', 5), ('pacific', 6), ('ocean', 7), ('lie', 8), ('eastern', 9), ('coast', 10), ('asian', 11), ('continent', 12), ('stretch', 13), ('sea', 14), ('okhotsk', 15), ('north', 16), ('china', 17), ('philippine', 18), ('south', 19), ('unite', 20), ('state', 21), ('america', 22), ('(usa)', 23), ('commonly', 24), ('know', 25), ('(us', 26), ('us)', 27), ('comprise', 28), ('federal', 29), ('district', 30), ('five', 31), ('major', 32), ('self-governing', 33), ('territory', 34), ('various', 35), ('possession', 36), ('england', 37), ('part', 38), ('kingdom', 39), ('officially', 40), (\"people's\", 41), ('republic', 42), ('(prc)', 43), (\"world's\", 44), ('populous', 45), ('population', 46), ('around', 47), ('billion', 48), ('india', 49), ('also', 50), ('india[e]', 51), ('korea', 52), ('region', 53), ('germany', 54), ('central', 55), ('western', 56), ('europe', 57), ('lying', 58), ('baltic', 59), ('alps', 60), ('lake', 61), ('constance', 62), ('high', 63), ('rhine', 64), ('russia', 65), ('russian', 66), ('federation', 67), ('transcontinental', 68), ('france', 69), ('french', 70), ('whose', 71), ('consist', 72), ('metropolitan', 73), ('several', 74), ('overseas', 75), ('italy', 76), ('italian', 77), ('european', 78), ('peninsula', 79), ('delimit', 80), ('surround', 81), ('brazil', 82), ('federative', 83), ('large', 84), ('latin', 85), ('canada', 86), ('northern', 87), ('spain', 88), ('spain[a][b]', 89), ('mostly', 90), ('australia', 91), ('commonwealth', 92), ('sovereign', 93), ('mainland', 94), ('australian', 95), ('tasmania', 96), ('numerous', 97), ('smaller', 98), ('indonesia', 99), ('(indonesian:', 100), ('republik', 101), ('[reˈpublik', 102), ('ɪndoˈnesia])[a]', 103), ('southeast', 104), ('indian', 105), ('mexico', 106), ('mexican', 107), ('(spanish:', 108), ('estados', 109), ('unidos', 110), ('mexicano', 111), ('southern', 112), ('portion', 113)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQOjHTfCeXjs",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### 2.1 ユークリッド距離\n",
        "\n",
        "各文書をベクトルで表すことが出来たので  \n",
        "ユークリッド距離が計算できる  \n",
        "この距離が小さければ似ていると考えることが出来る\n",
        "\n",
        "\\begin{equation}\n",
        "d(v_1,v_2) =(\\sum_{i=1}^n (v_{1i}-v_{2i})^2)^{\\frac{1}{2}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtEzuSDKZbpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean_distance(list_a, list_b):\n",
        "  diff_vec = np.array(list_a) - np.array(list_b)\n",
        "  return np.linalg.norm(diff_vec)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncJM5kYkEWUf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5cb438aa-6877-49c7-ec17-68a17fd4ee8f"
      },
      "source": [
        "for i in range(16):\n",
        "   list_0 = list(tfidf_vector[0])\n",
        "   list_i = list(tfidf_vector[i])\n",
        "   print(\"euclidean_distance(0,\",i,\") = \", euclidean_distance(list_0, list_i))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "euclidean_distance(0, 0 ) =  0.0\n",
            "euclidean_distance(0, 1 ) =  0.7568610948880183\n",
            "euclidean_distance(0, 2 ) =  1.0121429343618757\n",
            "euclidean_distance(0, 3 ) =  0.7126923005791219\n",
            "euclidean_distance(0, 4 ) =  0.8432973548323277\n",
            "euclidean_distance(0, 5 ) =  1.049789826669889\n",
            "euclidean_distance(0, 6 ) =  0.6801622588258939\n",
            "euclidean_distance(0, 7 ) =  0.8246258019334979\n",
            "euclidean_distance(0, 8 ) =  0.803525019398566\n",
            "euclidean_distance(0, 9 ) =  0.8246629509361179\n",
            "euclidean_distance(0, 10 ) =  0.8809987778032525\n",
            "euclidean_distance(0, 11 ) =  0.9367125179042475\n",
            "euclidean_distance(0, 12 ) =  0.8616972672884817\n",
            "euclidean_distance(0, 13 ) =  0.8165896066566779\n",
            "euclidean_distance(0, 14 ) =  0.8733968730080951\n",
            "euclidean_distance(0, 15 ) =  0.786732425078347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIyabGRTKGwA",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2 コサイン類似度\n",
        "\n",
        "ベクトルのなす角に着目して類似度を計算する  \n",
        "\n",
        "\\begin{equation}\n",
        "similarity(A, B)=cos(\\theta)=\\dfrac{\\sum_{i=1}^n A_iB_i}{{\\sqrt A}{\\sqrt B}}\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDhwqTN5yJGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(list_a, list_b):\n",
        "  \n",
        "  inner_prod = np.array(list_a).dot(np.array(list_b))\n",
        "  norm_a = np.linalg.norm(list_a)\n",
        "  norm_b = np.linalg.norm(list_b)\n",
        "  try:\n",
        "      return inner_prod / (norm_a*norm_b)\n",
        "  except ZeroDivisionError:\n",
        "      return 1.0"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNwrHm5TFsjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "9f7fdf0c-54ec-4bc1-a253-abd04d3bb846"
      },
      "source": [
        "for i in range(16):\n",
        "   list_0 = list(tfidf_vector[0])\n",
        "   list_i = list(tfidf_vector[i])\n",
        "   print(\"cosine_similarity(0,\",i,\") = \", cosine_similarity(list_0, list_i))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cosine_similarity(0, 0 ) =  0.9999999999999998\n",
            "cosine_similarity(0, 1 ) =  2.8873351476511364e-05\n",
            "cosine_similarity(0, 2 ) =  8.135936584958245e-05\n",
            "cosine_similarity(0, 3 ) =  0.14932426500054383\n",
            "cosine_similarity(0, 4 ) =  0.044358536973654335\n",
            "cosine_similarity(0, 5 ) =  0.14128529478592497\n",
            "cosine_similarity(0, 6 ) =  0.14207323255887835\n",
            "cosine_similarity(0, 7 ) =  0.09054479697520224\n",
            "cosine_similarity(0, 8 ) =  3.576950361677573e-05\n",
            "cosine_similarity(0, 9 ) =  0.025864847099641517\n",
            "cosine_similarity(0, 10 ) =  0.02050403304744488\n",
            "cosine_similarity(0, 11 ) =  0.02419449001683132\n",
            "cosine_similarity(0, 12 ) =  0.06346642101352062\n",
            "cosine_similarity(0, 13 ) =  0.08293620326441613\n",
            "cosine_similarity(0, 14 ) =  0.0732154433477262\n",
            "cosine_similarity(0, 15 ) =  0.013645710261608436\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}